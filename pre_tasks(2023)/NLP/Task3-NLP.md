# 人工智能考核文档
## 前言
首先恭喜各位完成上一轮考核。

本轮是本方向考核的最后一轮，我们的任务是学习数据集的制作和使用已有的预训练模型进行下游任务的微调。
## 考核任务
* 小说续写数据集制作：使用Python爬虫爬取小说网站获取一些小说文本，并将其制作成数据集FictionDataset（Torch.Dataset的派生类），爬取时注意平衡小说种类。
* 基于transformer库的bert-base-chinese进行下游训练使其能够续写小说，且逻辑通顺。
* （可选）使用Flask库为模型构建后端服务器，使模型能够部署到web应用上。

## 附
一个中文BERT预训练模型地址：https://www.huggingface.co/bert-base-chinese

## 算力补贴
本轮每人可有100元上限的服务器租用补贴。

## 考核提交
* 本次考核时长为2周
* 在第一周结束时会安排期中答辩，主要目的是推进进度和解答问题。
* 在第二周结束时提交PR，需要包含的内容如下：
  1. 模型以及爬虫的代码
  2. 一个名为"学习笔记"的**文件夹**，里面是本轮的学习笔记。
* 考核结束的答辩时需要演示最终成果
* 支持在第一周时提前交卷演示效果结束考核
