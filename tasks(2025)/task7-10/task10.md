# Task 10 星辰大海

## 一些思考

在当前的技术架构下，纯 LLM 已经发挥到了极致。因此，多模态技术应运而生。Google Gemini 正是基于多模态开发，原生支持理解视频和音频。

另一方面，CV 领域也面临瓶颈。曾经的 Sora 难以生成长视频，但近期 Sora2 的推出重新将 CV 技术推向新的高度。事实上，Sora2 采用的架构并非单纯的 Stable Diffusion 或 Transformer，而是采用了 DiT，一种结合了二者的技术。

或许无论对于 LLM 还是 CV 而言，现有的架构都已经接近瓶颈。

World Models 的概念悄然诞生——未来的 AI 发展方向或许不再局限于 Transformer。

## 学习目的

恭喜你已经完成了前面的学习规划。无论选择了哪条道路，你现在都已具备了扎实的 AI 能力。

然而，任何一位完成学习的人都会发现：你所掌握的，只是 AI 领域的一部分。

Task 10 是规划的最后一部分，也是你独立探索的开始。这一阶段，我们不再传授具体技术（How），而是共同探讨研究方向（Why）与研究内容（What）。你将从一个技术使用者，转变为一个需要思考技术边界与未来的研究者。

本阶段的学习目标包括：

1. **技术前沿探索**：探索 Transformer 之后的下一代架构、多模态统一建模、世界模型等前沿技术方向，理解 AI 如何从识别模式进化到理解世界运转规律
2. **理论基石追溯**：深入理解支撑 AI 大厦的数学与理论基础，包括泛化理论、因果推理、几何深度学习等核心谜题，探寻「为什么有效」背后的本质原因
3. **视野拓展与责任培养**：了解 AI 在科学、医疗等领域的应用，思考 AI 安全、对齐与伦理等议题，培养负责任的 AI 研究者意识

完成本阶段学习后，你将具备 AI 研究者的视野、AI 伦理学家的责任感、以及对 AI 未来发展的敏锐洞察力。你的 AI 学习之旅至此结束，而你在 AI 领域的探索，现在才刚刚开始。

## 学习内容

本阶段是开放式的、探索性的学习。以下是一些值得探索的前沿方向，它们共同构成了现代 AI 研究的版图。

### AI 安全与伦理（Safety & Ethics）

* 核心问题：如何确保 AI 系统的行为符合人类价值观和社会规范？
* 学习内容：

  * 对齐（Alignment）：超越 `RLHF/DPO`，理解对齐问题的本质。AI 的设计目标和实际优化目标之间可能存在偏差，如何从根本上让 AI 的目标与人类意图对齐是核心挑战。
  * 可解释性（Interpretability）：从防御恶意指令升级到理解 AI 的决策过程。研究如何打开神经网络的「黑箱」，确保 AI 的行为可预测、可控制。
  * 伦理（Ethics）：研究 AI 系统中的数据偏见问题、AI 创作的版权归属，以及 AI 对就业市场和社会结构的影响等宏观社会议题。

### 多模态技术（Multimodality）

* 核心问题：如何让 AI 像人类一样，使用多种感官统一理解世界？
* 学习内容：

  * 原生多模态（Native Multimodality）：深入理解 Google Gemini 系列的设计思想。它从一开始就使用统一的架构同时理解图像、音频、视频和文本，实现更深层次的跨模态理解。
  * 世界模拟（Text-to-Anything）：以 OpenAI Sora 为例，研究其强大的视频生成能力如何体现对物理世界规律的模拟。理解多模态技术不仅是理解，更是创造和预测。

### 具身智能（Embodied AI）

* 核心问题：如何让 AI 从虚拟世界进入物理世界，与真实环境交互？
* 学习内容：

  * 从数字到物理：这是 AI 从信息世界进入物理世界的关键步骤。AI 必须学习常识物理知识，并处理现实世界的不确定性。
  * 语言驱动行动（Language to Action）：学习 Tesla Bot 或 Google RT-2 等项目，研究如何使用 LLM 的语义理解与推理能力作为机器人的决策中枢，指导机器人完成复杂的物理任务。

### 世界模型（World Models）

* 核心问题：AI 能否在内部构建一个理解世界因果关系的动态虚拟模型？
* 学习内容：

  * 从关联到因果：这是 AI 认知能力的重要飞跃。传统 AI 擅长学习 A 和 B 经常一起出现（关联），而世界模型试图理解「因为 A，所以 B」（因果）。
  * 自我监督学习：以 Yann LeCun 的 JEPA（联合嵌入预测架构）为例，研究如何让 AI 通过观察世界的一部分来预测另一部分，从而在不依赖人类标注的情况下，自主学习世界运转的底层规律。

### 超越 Transformer：新一代序列模型架构

* 核心问题：Transformer 之后的下一代架构是什么？
* 学习内容：

  * 状态空间模型（State Space Models, SSMs）：以 Mamba 为代表的全新架构范式。不同于 Transformer 需要计算所有词元之间的「注意力」（计算复杂度为 `O(N^2)`），SSM 采用线性复杂度 `O(N)` 的机制，用一个巧妙的「状态」来记住前面的信息，然后线性地扫过整个序列。
  * 技术优势：处理超长序列（如一整本书或整个基因组）时，速度更快且更省内存。这是一种正在与 Transformer 激烈竞争的全新架构范式。

### 神经符号集成（Neuro-Symbolic AI）

* 核心问题：如何结合神经网络的感知能力和符号系统的推理能力？
* 学习内容：

  * 两种 AI 范式的融合：

    * 神经网络（Neural Networks）：擅长从数据中识别模式，处理连续、非结构化的信息（如图像识别、语音理解）。
    * 符号 AI（Symbolic AI）：擅长进行形式化推理、知识表示和逻辑演绎（如规则推理：`如果A>B，且B>C，那么A>C`）。
  * 技术核心：利用神经网络处理原始感知输入并提取特征表示，然后将其映射为符号表示，再通过符号推理系统进行逻辑推理、知识推理和决策规划。

### 几何深度学习（Geometric Deep Learning）

* 核心问题：能否从数学理论层面统一理解各种神经网络架构？
* 学习内容：

  * 核心思想：现实世界的数据具有内在的几何对称性。例如，图像具有平移不变性（图片中的物体无论出现在哪个位置，其语义保持不变），图结构数据具有置换不变性（节点重新排序不改变图的拓扑结构）。
  * 技术核心：基于群论和微分几何，设计能够保持数据对称性的等变网络架构。该理论框架揭示了 CNN 通过平移等变性处理欧几里得网格数据，GNN 通过置换等变性处理图数据的数学本质。这为设计适用于特定几何结构（如分子、3D 点云、流形）的神经网络提供了统一的理论指导。

### AI Agent 与群体智能

* 核心问题：如何让 AI 拥有自主规划和社交协作的能力？
* 学习内容：

  * 自主规划与执行：研究 AI Agent 如何理解模糊目标（如「帮我规划一次旅行」），然后自主分解任务、收集信息、制定计划并执行。
  * 多智能体协作（Multi-Agent Systems）：探索多个 AI Agent 如何像团队一样互相交流、分工协作，甚至竞争，共同完成单个智能体无法完成的复杂任务。

### 模型压缩与高效部署（Model Compression & Efficient Deployment）

* 核心问题：如何将数千亿参数的大规模模型高效部署在资源受限的边缘设备（如移动设备、嵌入式系统）上？
* 学习内容：

  * 量化（Quantization）：将模型参数从高精度浮点数（如 FP32）转换为低精度整数（如 INT8、INT4 甚至二值化），通过降低数值精度来减少存储开销和计算复杂度。
  * 剪枝（Pruning）：通过分析网络权重的重要性，移除冗余或贡献度低的连接和神经元，构建稀疏化网络以降低模型规模和推理延迟。
  * 知识蒸馏（Knowledge Distillation）：利用大型教师模型的软标签（概率分布）指导小型学生模型的训练，使学生模型在保持较小规模的同时逼近教师模型的性能。

### AI for Science：AI 驱动的科学研究

* 核心问题：如何利用 AI 加速基础科学研究，推动科学发现的范式转变？
* 学习内容：

  * 蛋白质结构预测与药物设计：深入研究 AlphaFold 系列如何利用深度学习预测蛋白质的三维空间结构。进一步学习如何使用生成式模型设计具有特定功能的新型蛋白质，以及基于结构的药物分子设计方法。
  * 基因组学与计算生物学（Genomics）：学习 AI 如何通过序列建模分析基因组数据，进行基因功能注释、疾病风险预测、药物靶点识别等任务，推动精准医学的发展。
  * 科学假说生成与实验设计：探索 AI 如何通过自然语言处理技术挖掘海量科学文献，识别知识缺口，自动生成科学假说，并利用强化学习优化实验设计方案。

### AI 医疗（AI in Healthcare）

* 核心问题：如何让 AI 成为医生的智能助手，提升医疗质量和效率？
* 学习内容：

  * 医学影像分析（Medical Imaging）：研究 AI 如何分析 X 光片、CT、MRI 等医学影像，辅助医生进行疾病诊断、识别病变区域和评估疾病进展。
  * 临床决策支持（Clinical Decision Support）：探索 AI 如何整合患者的多源数据（病历、检查结果、基因信息），为医生提供诊断建议和治疗方案推荐。
  * 个性化医疗（Precision Medicine）：研究如何基于患者的个体差异，为每位患者量身定制最优的治疗方案。

### 新一代计算硬件（Next-Gen AI Hardware）

* 核心问题：如何突破传统冯·诺依曼架构的性能瓶颈，设计更高效的 AI 专用计算硬件？
* 学习内容：

  * 神经形态计算（Neuromorphic Computing）：研究模拟生物神经元脉冲传递机制的新型计算架构，通过事件驱动、异步并行等特性实现超低功耗的边缘智能计算。
  * 光子计算（Photonic Computing）：探索利用光子作为信息载体的计算技术，利用光的高带宽、低延迟和低能耗特性，突破电子芯片的物理极限，实现超高速并行计算。

### 理论基石：深度学习的核心理论问题

> 这一部分探讨的是整个领域最核心、最深邃的未解之谜，它们是理论研究的关键挑战。

* 泛化理论的根本性问题：为什么过参数化的深度神经网络（参数数量远超训练样本数量）在训练数据上达到零误差后，仍能在测试集上表现出强泛化能力，而不会出现经典统计学习理论预测的过拟合现象？

  * 探索方向：「双下降」（Double Descent）现象的理论解释、神经正切核（Neural Tangent Kernel, NTK）理论、随机梯度下降（SGD）的隐式正则化机制。
* 规模定律的理论基础：为什么深度学习模型的性能随着模型规模、数据规模和计算量的增加呈现可预测的幂律关系（Scaling Law）？这种规律的理论边界和极限是什么？

  * 探索方向：基于统计物理学的相变理论分析模型能力的突变临界点、研究数据配比对模型性能的影响规律。
* 因果推理与深度学习的结合：如何使深度学习模型从学习统计相关性提升到理解变量间的因果关系，从而实现更可靠的推理和决策？

  * 探索方向：结构因果模型（Structural Causal Models, SCMs）与神经网络的融合、基于干预数据的因果表示学习。

## 作业

Task 10 没有固定的作业形式，你的产出是你的思想。

### 撰写一篇 AI 主题博客

* 选题：从本文档列出的方向中，选择一个你最感兴趣的议题进行深入研究。也完全欢迎你探索本文档未提及的其他 AI 相关议题。
* 要求：撰写一篇结构完整、逻辑清晰的博客文章。文章不仅应包含对该技术或议题的调研与综述，更重要的是，要包含你自己的独立观点、批判性思考或对未来的展望。
* 目标：完成一次从知识消费者到思想生产者的转变。

### 作业参考资料

对于本阶段的探索性学习，没有固定的教程。你需要学会像一名真正的研究者一样，从一手信息中学习。

* 顶级会议论文：前往 NeurIPS, ICML, ICLR, CVPR, ACL 等顶级会议官网，阅读你所选方向的最新论文。这是最前沿的一手资料。
* 预印本网站：在 arXiv.org 上追踪最新的研究进展，很多重要工作都会先在这里发布。
* 知名学者博客与社交媒体：关注 Yann LeCun, Andrej Karpathy, Lilian Weng, Sebastian Raschka 等领域专家的个人博客或 Twitter/X，他们经常会分享深刻的见解和最新的工作解读。
* 高质量技术解读：在 YouTube 频道（如 `Two Minute Papers`）、Hugging Face Blog、Distill.pub 等平台寻找对复杂概念的优质解读。
