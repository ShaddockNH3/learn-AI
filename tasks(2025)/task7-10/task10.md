# Task 10 星辰大海

## 一些思考

在当前的技术架构下，纯 LLM 已经发挥到了极致。因此，多模态技术应运而生。Google Gemini 正是基于多模态开发，原生支持理解视频和音频。

另一方面，CV 领域也面临瓶颈。曾经的 Sora 难以生成长视频，但近期 Sora2 的推出重新将 CV 技术推向新的高度。事实上，Sora2 采用的架构并非单纯的 Stable Diffusion 或 Transformer，而是采用了 DiT，一种结合了二者的技术。

或许无论对于 LLM 还是 CV 而言，现有的架构都已经接近瓶颈。

World Models 的概念悄然诞生——未来的 AI 发展方向或许不再局限于 Transformer。

## 学习目的

恭喜你已经完成了前面的学习规划。无论选择了哪条道路，你现在都已具备了扎实的 AI 能力。

然而，任何一位完成学习的人都会发现：你所掌握的，只是 AI 领域的一部分。

Task 10 是规划的最后一部分，也是你独立探索的开始。这一阶段，我们不再传授具体技术（How），而是共同探讨研究方向（Why）与研究内容（What）。你将从一个技术使用者，转变为一个需要思考技术边界与未来的研究者。

本阶段的学习目标包括：

1. **技术前沿探索**：探索 Transformer 之后的下一代架构、多模态统一建模、世界模型等前沿技术方向，理解 AI 如何从识别模式进化到理解世界运转规律
2. **理论基石追溯**：深入理解支撑 AI 大厦的数学与理论基础，包括泛化理论、因果推理、几何深度学习等核心谜题，探寻"为什么有效"背后的本质原因
3. **视野拓展与责任培养**：了解 AI 在科学、医疗等领域的应用，思考 AI 安全、对齐与伦理等议题，培养负责任的 AI 研究者意识

完成本阶段学习后，你将具备 AI 研究者的视野、AI 伦理学家的责任感、以及对 AI 未来发展的敏锐洞察力。你的 AI 学习之旅至此结束，而你在 AI 领域的探索，现在才刚刚开始。

## 学习内容

本阶段是开放式的、探索性的学习。以下是一些值得探索的前沿方向，它们共同构成了现代 AI 研究的版图。

### AI 安全与伦理（Safety & Ethics）

* **核心问题**：如何确保 AI 系统的行为符合人类价值观和社会规范？
* **学习内容**：

  * **对齐（Alignment）**：超越 `RLHF/DPO`，理解对齐问题的本质。AI 的设计目标和实际优化目标之间可能存在偏差，如何从根本上让 AI 的目标与人类意图对齐是核心挑战。
  * **可解释性（Interpretability）**：从防御恶意指令升级到理解 AI 的决策过程。研究如何打开神经网络的「黑箱」，确保 AI 的行为可预测、可控制。
  * **伦理（Ethics）**：研究 AI 系统中的数据偏见问题、AI 创作的版权归属，以及 AI 对就业市场和社会结构的影响等宏观社会议题。

### 多模态技术（Multimodality）

* **核心问题**：如何让 AI 像人类一样，使用多种感官统一理解世界？
* **学习内容**：

  * **原生多模态（Native Multimodality）**：深入理解 **Google Gemini 系列**的设计思想。它从一开始就使用统一的架构同时理解图像、音频、视频和文本，实现更深层次的跨模态理解。
  * **世界模拟（Text-to-Anything）**：以 **OpenAI Sora** 为例，研究其强大的视频生成能力如何体现对物理世界规律的模拟。理解多模态技术不仅是理解，更是创造和预测。

### 具身智能（Embodied AI）

* **核心问题**：如何让 AI 从虚拟世界进入物理世界，与真实环境交互？
* **学习内容**：

  * **从数字到物理**：这是 AI 从信息世界进入物理世界的关键步骤。AI 必须学习常识物理知识，并处理现实世界的不确定性。
  * **语言驱动行动（Language to Action）**：学习 **Tesla Bot** 或 **Google RT-2** 等项目，研究如何使用 LLM 的思考和规划能力作为机器人的「大脑」，指挥机器人完成复杂的物理任务。

### 世界模型（World Models）

* **核心问题**：AI 能否在内部构建一个理解世界因果关系的动态虚拟模型？
* **学习内容**：

  * **从关联到因果**：这是 AI 认知能力的重要飞跃。传统 AI 擅长学习 A 和 B 经常一起出现（关联），而世界模型试图理解「因为 A，所以 B」（因果）。
  * **自我监督学习**：以 Yann LeCun 的 JEPA（联合嵌入预测架构）为例，研究如何让 AI 通过观察世界的一部分来预测另一部分，从而在不依赖人类标注的情况下，自主学习世界运转的底层规律。

### 超越 Transformer：新一代序列模型架构

* **核心问题**：Transformer 之后的下一代架构是什么？
* **学习内容**：

  * **状态空间模型（State Space Models, SSMs）**：以 **Mamba** 为代表的全新架构范式。不同于 Transformer 需要计算所有词元之间的「注意力」（计算复杂度为 `O(N^2)`），SSM 采用线性复杂度 `O(N)` 的机制，用一个巧妙的「状态」来记住前面的信息，然后线性地扫过整个序列。
  * **技术优势**：处理超长序列（如一整本书或整个基因组）时，速度更快且更省内存。这是一种正在与 Transformer 激烈竞争的全新架构范式。

### 神经+符号：让 AI 真正学会「思考」

* **核心问题**：如何结合神经网络的感知能力和符号系统的推理能力？
* **学习内容**：

  * **两种 AI 思想的融合**：

    * **神经网络（Neuro）**：擅长从数据中识别模式，处理模糊的信息（如看懂一张图）。
    * **符号 AI（Symbolic）**：擅长进行严密的推理、规划和解释（如逻辑推理：`如果A>B，且B>C，那么A>C`）。
  * **技术核心**：用神经网络处理现实世界的感知输入，然后把结果转换成符号，交给专门的「逻辑推理引擎」去进行真正的、可解释的思考和规划。

### 几何深度学习：为 AI 构建统一的「物理定律」

* **核心问题**：能否从数学理论层面统一理解各种神经网络架构？
* **学习内容**：

  * **核心思想**：现实世界的数据自带几何「对称性」。例如，图片里的猫无论平移到哪个位置都还是猫（平移不变性），图结构数据的节点交换顺序后图的本质不变（置换不变性）。
  * **技术核心**：设计天生就尊重这些数据对称性的网络架构。它揭示了 **CNN** 之所以成功是因为它尊重平移对称性，而 **GNN** 尊重置换对称性。它提供了一套统一的数学「语言」，去设计更适合特定数据结构（如分子、3D 模型、流形）的神经网络。

### AI Agent 与群体智能

* **核心问题**：如何让 AI 拥有自主规划和社交协作的能力？
* **学习内容**：

  * **自主规划与执行**：研究 AI Agent 如何理解模糊目标（如「帮我规划一次旅行」），然后自主分解任务、收集信息、制定计划并执行。
  * **多智能体协作（Multi-Agent Systems）**：探索多个 AI Agent 如何像团队一样互相交流、分工协作，甚至竞争，共同完成单个智能体无法完成的复杂任务。

### 算法级效率极限压缩：把大象装进火柴盒

* **核心问题**：如何把几千亿参数的庞大模型，高效地部署在手机甚至手表上？
* **学习内容**：

  * **量化（Quantization）**：把模型里原来用 32 位浮点数表示的参数，用 8 位、4 位甚至 1 位的整数来表示，大幅减小模型体积。
  * **剪枝（Pruning）**：在训练好的巨大网络里，找到那些「无足轻重」的连接并剪掉，让网络变得更稀疏、更轻巧。
  * **知识蒸馏（Knowledge Distillation）**：训练一个小的「学生」模型去模仿一个大的「老师」模型的输出，让学生学到老师的「精髓」。

### AI for Science：AI 成为科学发现的新范式

* **核心问题**：如何让 AI 理解「生命的语言」，助力基础科学研究？
* **学习内容**：

  * **蛋白质折叠与药物设计**：深入研究 **AlphaFold** 系列如何用 AI 预测蛋白质的 3D 结构。进一步学习如何使用 AI 设计全新的蛋白质，甚至直接设计能够治疗疾病的药物分子。
  * **基因组学（Genomics）**：学习 AI 如何分析基因序列，预测疾病风险，寻找遗传病的治疗线索，探索如何「读懂」生命的密码本。
  * **自动化假说生成与验证**：探索 AI 如何通过阅读海量文献，自动提出新的科学假说，并设计实验方案进行验证。

### AI 医疗（AI in Healthcare）

* **核心问题**：如何让 AI 成为医生的智能助手，提升医疗质量和效率？
* **学习内容**：

  * **医学影像分析（Medical Imaging）**：研究 AI 如何分析 X 光片、CT、MRI 等医学影像，辅助医生进行疾病诊断、识别病变区域和评估疾病进展。
  * **临床决策支持（Clinical Decision Support）**：探索 AI 如何整合患者的多源数据（病历、检查结果、基因信息），为医生提供诊断建议和治疗方案推荐。
  * **个性化医疗（Precision Medicine）**：研究如何基于患者的个体差异，为每位患者量身定制最优的治疗方案。

### 新一代计算硬件（Next-Gen AI Hardware）

* **核心问题**：如何为 AI 设计更高效的「大脑」，突破算力瓶颈？
* **学习内容**：

  * **神经形态计算（Neuromorphic Computing）**：研究模仿人脑神经元工作方式的新型芯片，实现低功耗、高能效的边缘计算。
  * **光子计算（Photonic Computing）**：探索用光代替电进行计算的技术，利用光的超高速度和低能耗，为 AI 运算带来质的飞跃。

### 理论基石：深度学习的根本性谜题

> 这一部分探讨的是整个领域最核心、最深邃的未解之谜，它们是理论研究的圣杯。

* **泛化理论的黑洞**：为什么拥有数十亿参数的模型，在远少于参数数量的数据上训练，不仅没有过拟合，反而获得了强大的泛化能力？

  * *探索方向*：**「双下降」（Double Descent）** 现象、**神经正切核（NTK）**、**SGD 的隐式偏置**。
* **涌现的物理学**：为什么 AI 的能力会随着规模的扩大呈现出可预测的幂律增长（Scaling Law）？这些增长的尽头是什么？

  * *探索方向*：用统计物理学理论寻找能力的\*\*「相变」临界点\*\*、探索**数据最优混合比**。
* **因果的圣杯**：如何让 AI 从学习「相关性」进化到理解「因果性」，摆脱「超级鹦鹉」的宿命？

  * *探索方向*：**结构化因果模型（SCMs）与神经网络的结合**、**从干预中学习因果关系**。

## 考核内容

Task 10 没有固定的作业形式，你的产出是你的思想。

### 撰写一篇 AI 主题博客

* **选题**：从本文档列出的方向中，选择一个你最感兴趣的议题进行深入研究。也完全欢迎你探索本文档未提及的其他 AI 相关议题。
* **要求**：撰写一篇结构完整、逻辑清晰的博客文章。文章不仅应包含对该技术或议题的调研与综述，更重要的是，要包含**你自己的独立观点、批判性思考或对未来的展望**。
* **目标**：完成一次从知识消费者到思想生产者的转变。

## 推荐资源

对于本阶段的探索性学习，没有固定的教程。你需要学会像一名真正的研究者一样，从一手信息中学习。

* **顶级会议论文**：前往 **NeurIPS, ICML, ICLR, CVPR, ACL** 等顶级会议官网，阅读你所选方向的最新论文。这是最前沿的一手资料。
* **预印本网站**：在 **arXiv.org** 上追踪最新的研究进展，很多重要工作都会先在这里发布。
* **知名学者博客与社交媒体**：关注 **Yann LeCun, Andrej Karpathy, Lilian Weng, Sebastian Raschka** 等领域专家的个人博客或 Twitter/X，他们经常会分享深刻的见解和最新的工作解读。
* **高质量技术解读**：在 **YouTube** 频道（如 `Two Minute Papers`）、**Hugging Face Blog**、**Distill.pub** 等平台寻找对复杂概念的优质解读。
