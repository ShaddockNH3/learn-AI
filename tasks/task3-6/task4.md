# task4 机器学习

## 学习目的

欢迎来到第四轮考核。在此之前，你已经对Python和基础的AI概念有了初步的认识。

AI的方向有很多，但大体分为两种，计算机视觉（CV）以及自然语言处理（NLP）。

然而，无论是CV，NLP还是其他方向，它们的训练都有着共同的基石——反向传播。

诚然，使用现代成熟的库，比如说pytorch，可以有效地避免这些问题，然而我们的要求不是让你成为使用“魔法”的机器人，而是让你成为一个理解“魔法”内部原理的大师。

作为计算机专业的学生，我们的核心竞争力在于**深入理解基本原理，并具备从零实现算法、调试和优化模型的能力**本轮考核将是你迈向这一目标的关键一步。

当然，对于其他的一些机器学习算法（也就是和深度学习，神经网络在技术原理和路线上有所不同的），只需要了解然后掌握一些基本的原理，会使用[sk-learn](https://scikit-learn.org/stable/)，不需要从零开始手敲，我们的目的在于更前沿的深度学习。

这里简单解释一下，与深度学习技术原理不同，原理类似类似的机器学习，以及深度学习的区别。他们最核心的区别和联系，就在于如何学习和利用数据的“特征”。

比如说与深度学习技术原理不同的决策树和随机森林，它们更像一个逻辑清晰的侦探，会根据我们事先定义好的特征（比如“天气好不好？”，“温度高不高？”），通过一系列“是/否”的判断，一步步推理出结论，整个决策过程是直白且有迹可循的。

而与神经网络原理更近一些的SVM（支持向量机），它就不再是简单地做判断题了，而是更抽象地试图在数据之间找到一个最完美的“分界线”（也就是超平面），这个通过数学优化来寻找复杂边界的思想，与神经网络调整权重来划分数据的内在逻辑有相似之处。

但深度学习最根本的飞跃在于，它拥有了强大的“自动特征提取”能力，我们不再需要像对待前两者那样绞尽脑汁地手动设计特征。而深度学习神经网络自己就能从最原始的数据中，逐层抽象和学习出解决问题所需要的最高效特征，这正是它与所有传统机器学习算法最关键的不同。

## 学习内容

本轮的核心学习内容将围绕一系列经典的机器学习模型与概念展开，最终全部导向对神经网络核心的理解：

* **分类器基础**: K-Nearest Neighbor (k-NN), Support Vector Machine (SVM), Softmax Classifier
* **神经网络核心**: Two-Layer Neural Network, Fully-Connected Networks
* **特征工程**: Image Features (Histogram of Oriented Gradients, Color Histograms)

## 学习要求

本轮学习内容对新手而言具有相当的挑战性，尤其对于首次接触全英文课程的同学。但这正是我们希望你克服的第一个障碍。在AI领域，**英文阅读能力不是加分项，而是必需品**，因为绝大多数前沿论文、官方文档和高质量社区讨论都以英文为载体。我们鼓励你勇敢地面对这个挑战，并善用工具辅助自己。

此外，本轮需要一些前置知识：线性代数、微积分、numpy以及python编程。

后两者已经在前几轮涉及到，前两个，如果学校课程没有开的话（对于大一生，偏导部分在高数大一下教），可以看下一节的推荐教程。

## 推荐教程

* **核心课程**: **Stanford CS231n: Convolutional Neural Networks for Visual Recognition**

  * [课程英文主页 (Notes & Assignments)](https://cs231n.github.io/)
  * [课程中文翻译 (Notes)](https://zhuanlan.zhihu.com/p/21930884) （采用python2.7版本，已过时，可作为辅助理解材料）

* **sk-learn**: [sk-learn官网学习](https://scikit-learn.org/stable/user_guide.html)（官方手册够用了）

* **前置知识以及辅助资料**:

  1. 前三轮知识的学习，尤其是numpy，pandas和matplotlib库。py基础不必多说，爬虫的作用主要是未来自己进行AI方面研究时，有能力去补全数据或爬取自己想要的数据。
  2. 多元函数复合求导（求偏导），具体的内容在高数B下，可参考[宋浩高等数学](https://www.bilibili.com/video/BV1Eb411u7Fw?spm_id_from=333.788.videopod.episodes&vd_source=0272bb7dd0d8d9302c55fc082442b9e3&p=96)，直至可以完成一些简单的求偏导内容。
  3. 线性代数，计算机专业的同学大一上已经开了线性代数。无论对于学没学过的同学，都可以参考[线性代数的本质](https://www.bilibili.com/video/BV1Ys411k7yQ/?spm_id_from=333.337.search-card.all.click&vd_source=0272bb7dd0d8d9302c55fc082442b9e3)该系列视频完成对线性代数的熟悉。
  4. **NumPy**: 作业将大量使用NumPy进行向量化计算。请务必完成 [CS231n官方NumPy教程](https://cs231n.github.io/python-numpy-tutorial/)。对于不熟悉的API，学会使用搜索引擎和AI工具进行查询。
  5. **矩阵求导**: 这是理解反向传播数学原理的关键。不必畏惧，你只需掌握基础的求偏导知识即可入门。推荐通过以下资源学习：
     * [B站视频教程](https://www.bilibili.com/video/BV1av4y1b7MM/)
     * [知乎文章讲解](https://zhuanlan.zhihu.com/p/273729929)
  6. **课程视频**:
     * CS231n的[课程视频](https://www.bilibili.com/video/BV1b1agz5ERC/?spm_id_from=333.337.search-card.all.click&vd_source=0272bb7dd0d8d9302c55fc082442b9e3)是很好的补充材料。
     * 如果觉得CS231n的数学推导过多，建议观看 [李宏毅老师的机器学习课程](https://www.bilibili.com/video/BV1Wv411h7kN/)，该课程更侧重于从直观上理解模型原理。
     * [吴恩达老师的机器学习视频](https://www.bilibili.com/video/BV1owrpYKEtP/?spm_id_from=333.337.search-card.all.click&vd_source=0272bb7dd0d8d9302c55fc082442b9e3)
     * 一些经典的机器学习方法，包括与神经网络在技术原理和路线上有所不同的[经典机器学习方法](https://www.bilibili.com/video/BV1T84y167U9/?spm_id_from=333.337.search-card.all.click&vd_source=0272bb7dd0d8d9302c55fc082442b9e3)
---

## 一个可能的学习路径

1. **适应英文环境**: 积极适应全英文的学习材料。建议不要使用浏览器的全文自动翻译，可以安装划词翻译插件，强制自己阅读原文，只在遇到生词时进行查询。
2. **啃下课程笔记 (Notes)**: CS231n的课程Notes是完成作业的知识宝库，内容详实且深入。请务必花费时间仔细阅读，这是你理解所有模型原理的基础。
3. **攻克数学难点**: 遇到矩阵求导等数学难题时，不要直接跳过。利用推荐的视频和文章，静下心来推导一两个简单的例子，你会发现它并没有想象中那么可怕。
4. **建立交流社区**: 我们希望将考核群打造成一个高效的刷课社区。请积极在群里讨论问题，尤其是数学和理论方面的内容。交流能极大地提高学习效率。**但严禁直接分享或抄袭代码。**

## 作业

### 作业1

**核心任务：完成 [CS231n Assignment 1](https://cs231n.github.io/assignments2025/assignment1/)**

本次作业是一次回归本源的旅程，将引导你从零开始，亲手实现多个经典的机器学习与神经网络模型，为后续更复杂的挑战奠定坚实的基础。

#### 第一部分：经典图像分类器 (Classic Image Classifiers)

在这一部分，你将深入理解图像分类的基石，通过手动实现三个经典的线性分类器来构建对模型内部工作原理的直观认知。你需要：

* 实现一个简单的 **k-近邻 (k-NN)** 分类器，体验非参数方法的直观与简洁。
* 为强大的 **支持向量机 (SVM)** 推导并实现其损失函数与梯度的向量化计算。
* 为多分类问题实现 **Softmax** 分类器，包括其损失函数与梯度的计算。
* 使用**随机梯度下降 (SGD)** 算法来优化你实现的SVM和Softmax模型，并学习如何调整超参数以获得更好的性能。

#### 第二部分：你的第一个神经网络 (Your First Neural Network)

在掌握了线性分类器的基础上，你将迎来一次质的飞跃，从零开始构建一个完整的神经网络。你需要：

* 搭建一个**两层的全连接神经网络**，并实现其**前向传播 (forward pass)** 过程，计算出分类得分。
* 完成整个作业中最核心、最关键的一步：为你的神经网络手动实现**反向传播 (backpropagation)** 算法，计算所有可训练参数的梯度。
* 最后，在经典的 **CIFAR-10** 数据集上训练并验证你亲手搭建的所有模型（k-NN, SVM, Softmax, 两层神经网络），直观地比较它们的性能表现。

这个过程将强制你告别“调包”，直面算法的每一个实现细节，从而真正建立起对深度学习核心原理的深刻认知。

### 作业2 掌握 scikit-learn 库并实践经典机器学习算法（选做）

**核心任务：以Kaggle经典入门赛 [Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) 为实战项目，熟练运用 `scikit-learn` 完成一个完整的机器学习流程。**

sk-learn是一个强大的机器学习库，内部封装了很多经过验证的经典的机器学习算法，在数学建模竞赛等场合大放异彩。

我们后续是探索更前沿的深度学习，这部分内容只需要浅尝辄止，不需要深入研究它内部复杂的实现原理，重点是了解它能做什么，并在未来需要的时候，能够熟练地查阅官方教程，直接调用它为我们准备好的强大接口（API）来解决问题。

推荐去了解一下以下这些经典的机器学习算法，它们与我们主攻的深度学习（神经网络）在技术原理和路线上有所不同，但在许多场景下（尤其是数学建模和数据竞赛中）依然是非常强大和高效的工具：

1. [决策树](https://scikit-learn.org/stable/modules/tree.html)
2. [随机森林](https://scikit-learn.org/stable/modules/ensemble.html)

本次作业将引导你直面一个真实的预测任务，你将不再使用“玩具”数据集，而是要亲手处理带有缺失和噪音的原始数据，最终提交你的预测结果，体验一次完整的数据科学竞赛之旅。

#### 第一部分：数据探索与预处理 (Data Exploration & Preprocessing)

在这一部分，你将扮演数据侦探的角色，清洗和整理泰坦尼克号的乘客数据，为后续的模型训练铺平道路。

* **加载与分析**：使用 `pandas` 库加载 `train.csv` 数据，并进行探索性数据分析（EDA），理解每个特征的含义，并找出其中的缺失值（如`Age`, `Embarked`等）。
* **数据清洗**：对缺失值进行合理的填充（例如，使用均值、中位数或众数）。
* **特征工程**：将非数值的类别特征（如`Sex`, `Embarked`）转换为模型可以理解的数值格式（例如，独热编码或标签编码）。此外，你需要决定哪些特征（如`Name`, `Ticket`）对于预测生存率是无关的，并将其舍弃。

#### 第二部分：训练与评估多种分类模型 (Training & Evaluating Models)

在准备好“食材”后，你将使用 `sk-learn` 训练多种模型，并比较它们在预测乘客生还率上的表现。

* **数据划分**：使用 `sklearn.model_selection.train_test_split` 将你的训练数据划分为新的训练集和验证集，以便客观地评估模型性能。
* **模型训练**：至少实现以下模型中的三种，并特别推荐尝试**随机森林**，因为它在该类任务中通常表现出色：

  * 逻辑回归 (`sklearn.linear_model.LogisticRegression`)
  * K-近邻 (`sklearn.neighbors.KNeighborsClassifier`)
  * 支持向量机 (`sklearn.svm.SVC`)
  * **随机森林 (`sklearn.ensemble.RandomForestClassifier`)**
* **模型评估**：在验证集上评估每一个模型，使用 `sklearn.metrics.accuracy_score` 和 `sklearn.metrics.classification_report` 来比较它们的准确率、精确度、召回率等指标，并选出表现最佳的模型。

#### 第三部分：模型调优与生成提交文件 (Tuning & Submission)

为了在Kaggle排行榜上获得更好的名次，你需要对你的最佳模型进行精细的打磨。

* **超参数调优**：使用 `sklearn.model_selection.GridSearchCV` 对你在第二部分中选出的最佳模型进行自动化超参数搜索，找到最优的参数组合。
* **最终预测**：用你找到的最佳参数，在**全部**的 `train.csv` 数据上重新训练最终模型。
* **生成提交文件**：加载并用**完全相同**的预处理步骤处理 `test.csv` 数据，使用你最终训练好的模型进行预测，并按照Kaggle要求的格式（包含`PassengerId`和`Survived`两列）生成 `submission.csv` 文件。

完成这个作业后，你不仅将熟练掌握 `sk-learn` 的核心用法，更将获得一次宝贵的、端到端解决实际问题的项目经验。

---

## 作业要求

1. **严禁抄袭**。独立完成是本次作业的底线要求。
2. **善用工具**。遇到问题时，首先尝试通过搜索引擎、官方文档和AI助手解决。如果仍然无法解决，欢迎在群里进行有深度的提问。在提问前，强烈建议阅读[《提问的智慧》](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way)。
3. **拥抱AI，但保持思考**。不限制使用ChatGPT等大语言模型工具，但你必须确保能完全理解模型生成的每一行代码。建议在由AI生成的关键代码块旁，用注释标明其来源及你的理解。
4. **规范化提交**。所有作业均需通过Git提交到你个人的GitHub仓库中，并按照课程要求的方式提交PR。

## 作业提交方式

1. 在你的个人GitHub仓库中为本次作业创建一个新的文件夹 (例如 `task4-cs231n-a1`)。
2. 将你完成的所有代码（`.py`和`.ipynb`文件）上传到该文件夹。
3. 通过Pull Request的方式，在课程仓库的 `solutions.md` 文件中更新你的仓库地址。
