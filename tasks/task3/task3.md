# Task 3

## 学习目的

在这一轮，我们将暂时从深奥的算法理论中抽身，专注于掌握处理、计算和理解数据的核心技能。

你将学习如何使用 Numpy 来铸造强大、高效的数值数组，这是我们所有数据魔法的底层力量源泉；你将学习如何使用 Pandas 像魔术师一样轻松地清洗、转换和分析海量数据；同时，你还将学会使用 Matplotlib 等可视化工具，将枯燥的数字变成直观、生动的图表，让数据“开口说话”。

这些工具是未来你探索AI世界、进行特征工程、分析实验结果不可或缺的基石。熟练掌握它们，你的AI冒险之旅将事半功倍！

#### **学习内容**

* **数据科学基本工具学习**

  * **Pandas 的深度应用**:

    * 数据读取与写入 (`read_csv`, `to_csv`, etc.)
    * 数据清洗 (处理缺失值、重复值、异常值)
    * 数据筛选与高级索引 (`loc`, `iloc`, 布尔索引)
    * 数据的处理与变换 (`groupby`, `apply`, `merge`)
  * **数据可视化入门**:

    * 学习使用 `matplotlib` 绘制常见的统计图形。
    * （选学）了解 `plotly`、`pyecharts` 等更现代、更具交互性的可视化库。

#### **推荐教程**

* **快速上手指南**

  1. **Numpy 速成 (CS231n)**: [Python Numpy Tutorial](https://cs231n.github.io/python-numpy-tutorial/)

  2. **PyTorch 速成 (cs224n)**: [PyTorch Quickstart](https://colab.research.google.com/drive/1Pz8b_h-W9zIBk1p2e6v-YFYThG1NkYeS?usp=sharing)

  这里只是放在这里，暂时不要求掌握，也没那么快用到pytorch之类的现代工具。

  3. **菜鸟教程 (中文)**:

     * [Pandas 教程](https://www.runoob.com/pandas/pandas-tutorial.html)
     * [Numpy 教程](https://www.runoob.com/numpy/numpy-tutorial.html)

  4. **kaggle (Kaggle Learn)**

  * [Kaggle Learn](https://www.kaggle.com/learn)

  **Pandas** 和 **Data Visualization** 这两门课，非常适合动手学习，强烈推荐

  5. **深度探索 (学有余力的同学)**

  * [UC Berkeley Data 8](https://www.data8.org/): 伯克利大学经典的数据科学入门课。
  * [UC Berkeley Data 100](https://ds100.org/): 更深入的数据科学原理与技术。

  6. **官方权威手册 (当你需要精确查阅时)**

  * [Pandas 官方文档](https://pandas.pydata.org/docs/)
  * [Numpy 官方文档](https://numpy.org/doc/stable/)

---

## **作业**

### **作业1: 福大教务处情报分析任务 (Pandas)**

将上一轮作业的作业1爬取道德数据进行分析与可视化

#### **要求**

1. 请使用 **Jupyter Notebook** 的形式完成你的代码与分析报告，这能让你的分析过程一目了然。
2. **“通知人”都有谁？** 统计所有出现过的“通知人”，并计算他们各自发布的通知数量占总数的比例。
3. **附件下载与通知人的关系？** 分析附件的下载次数与通知人是否存在某种联系。比如，是不是某些特定部门发布的通知，附件下载量总是特别高？
4. **通知发布的高峰期？** 统计每天发布的通知数量，分析一下，通常在学期的哪个时间段，通知会变得特别密集？
5. **自由探索！** 根据你对数据的好奇心，自行思考一个你感兴趣的问题，并进行数据分析。（例如：通知的标题长度和阅读量/下载量有关吗？标题中出现哪些关键词会更受关注？）
6. **让图表说话！** 尝试使用 `matplotlib` 或其他可视化工具，将你在问题 **3** 和 **4** 中的分析结果以图表的形式呈现出来。

### **作业2: 帮助ShaddockNH3重拾青春回忆 (Matplotlib)**

最近ShaddockNH3在整理旧物时，突然怀念起了他的高中生活。他依稀记得生物必修二里，有一张关于种群数量分析的“S”形曲线图，那优美的曲线令他记忆深刻。可惜，他已经在高考结束的第二天就把所有的课本都卖掉啦！(╥﹏╥)

现在，他郑重地拜托你，用代码为他重现当时的记忆。

#### **背景知识**

那条美丽的曲线就是大名鼎鼎的 **Logistic 函数**，它的数学表达式是：
$f(x) = \frac{L}{1 + e^{-k(x-x_0)}}$
其中：

* `L` 代表曲线的饱和值（最大值）。
* `k` 代表曲线的陡峭程度。
* `x0` 代表S形曲线中点的位置。

#### **要求**

1. 请使用 `matplotlib` 绘制一个标准的 Logistic 函数图像，其中参数设置为：`L=1`, `k=1`, `x0=0`。
2. 为了帮助ShaddockNH3更好地理解，请尝试在同一张图或多张子图中，绘制不同 `L`、`k`、`x0` 参数下的 Logistic 函数，并用图例或文字简单说明，改变每个参数是如何影响函数形状的。

> 其实这个函数在深度学习里经常被使用到

### 作业3：矩阵操作与数据分析

**要求:**

1. **数组创建:** 创建一个形状为 `(10, 10)` 的NumPy数组，命名为 `data_matrix`，使其包含从0到99的连续整数。

   * 应使用 `numpy.arange` 和 `numpy.reshape` 方法完成。

2. **子矩阵提取:** 从 `data_matrix` 中提取出位于中心的 `4x4` 子矩阵。

3. **条件筛选与赋值:**

   * 在 `data_matrix` 中定位所有数值大于75的元素。
   * 使用布尔索引（Boolean Indexing）将这些元素的值全部重置为0。此操作禁止使用任何形式的显式循环。

4. **向量化运算:** 对上一步处理后的 `data_matrix` 进行整体缩放，将矩阵中的所有元素乘以 `0.8`。此操作应直接在原数组上（in-place）完成。

5. **数据聚合与定位:**

   * 找出最终矩阵中的最大值。
   * 确定该最大值在矩阵中的行和列索引。
   * **提示:** 可结合使用 `numpy.argmax` 和 `numpy.unravel_index` 来高效完成定位。

---

### 作业4： 广播机制与向量化距离计算

**目标:** 考察对NumPy核心特性——广播（Broadcasting）机制的理解与应用，以实现高效的向量化计算。

**要求:**

1. **数据生成:**

   * 创建数组 `points_A`，形状为 `(5, 2)`，代表5个点的二维坐标。
   * 创建数组 `points_B`，形状为 `(8, 2)`，代表另外8个点的二维坐标。
   * 两个数组的数据均使用 `numpy.random.randint` 在 `[0, 100]` 区间内随机生成。

2. **距离矩阵计算:**

   * 计算 `points_A` 中每个点到 `points_B` 中每个点的欧几里得距离，最终生成一个形状为 `(5, 8)` 的距离矩阵 `distance_matrix`。
   * `distance_matrix[i, j]` 应表示 `points_A[i]` 与 `points_B[j]` 之间的距离。
   * **核心要求: 此过程严禁使用任何形式的显式 `for` 或 `while` 循环。** 必须利用NumPy的广播机制完成。
   * **提示:** 考虑使用 `numpy.newaxis` 或 `numpy.reshape` 调整数组维度以触发广播。欧几里得距离公式为 `sqrt(Σ(p_i - q_i)²) `。

3. **轴向数据聚合:**

   * 对于 `points_A` 中的每一个点，从 `distance_matrix` 中找出其与 `points_B` 中所有点的最小距离。
   * 结果应为一个长度为5的一维数组。
   * **提示:** 研究 `numpy.min` 函数的 `axis` 参数。

4. **复合条件查询:**

   * 找出 `points_B` 中，与 `points_A` 中**至少一个点**的距离小于20的所有点的**索引**。
   * **提示:** 综合运用布尔掩码、`numpy.any` 以及 `numpy.where`。

---

### 作业5： 图像数据的数组表示与操作

**要求:**

1. **数据初始化与维度变换:**

   * 首先，通过 `numpy.random.randint(0, 256, size=(200, 300))` 创建一个二维数组，用以模拟一个 `200x300` 像素的灰度图像 `grayscale_image`。
   * 随后，将此二维灰度图像转换为一个 `(200, 300, 3)` 的三维RGB图像 `color_image`，要求R、G、B三个通道的数值与原始灰度值完全相同。
   * **提示:** 可使用 `numpy.stack` 或其他维度扩展技术。

2. **基于矩阵乘法的滤镜实现:**

   * 为 `color_image` 实现一个“复古色（Sepia）”滤镜。该滤镜通过对每个像素的 `[R, G, B]` 向量应用一次线性变换实现。变换矩阵如下：

     ```python
     sepia_matrix = np.array([
         [0.393, 0.769, 0.189],
         [0.349, 0.686, 0.168],
         [0.272, 0.534, 0.131]
     ])
     ```
   * **核心要求: 必须使用NumPy的矩阵乘法 (`@` 或 `numpy.dot`) 来完成对整个图像的变换，严禁使用循环遍历像素。**
   * 计算结果可能会超出 `[0, 255]` 范围，需使用 `numpy.clip` 函数进行截断。

3. **基于元素级运算的色彩增强:**

   * 实现一个简化的“过饱和”效果。其算法步骤如下：

     1. 根据公式 `L = 0.299*R + 0.587*G + 0.114*B` 计算图像每个像素的亮度 `L` (Luminance)。
     2. 对于每个颜色通道 `C` (C为R, G或B)，应用饱和度增强公式 `C_new = L + alpha * (C_old - L)`，其中 `alpha` 为饱和度因子（例如，取 `1.5`）。
   * **核心要求: 整个过程必须是向量化的元素级运算。**
   * 同样，对最终结果进行 `[0, 255]` 的截断。

4. **利用数组切片添加特效:**

   * 为原始的 `color_image` 添加一个宽度为20像素的水平渐变边框。
   * 左侧20像素的边框应从纯黑（值=0）线性渐变到图像的原始像素值。
   * 右侧20像素的边框应从图像的原始像素值线性渐变到纯白（值=255）。
   * **提示:** `numpy.linspace` 可用于生成渐变序列。


## 作业要求

1. **严禁抄袭**。独立完成是本次作业的底线要求。
2. **善用工具**。遇到问题时，首先尝试通过搜索引擎、官方文档和AI助手解决。如果仍然无法解决，欢迎在群里进行有深度的提问。在提问前，强烈建议阅读[《提问的智慧》](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way)。
3. **拥抱AI，但保持思考**。不限制使用ChatGPT等大语言模型工具，但你必须确保能完全理解模型生成的每一行代码。建议在由AI生成的关键代码块旁，用注释标明其来源及你的理解。
4. **规范化提交**。所有作业均需通过Git提交到你个人的GitHub仓库中，并按照课程要求的方式提交PR。

## 作业提交方式

1. 在你的个人GitHub仓库中为本次作业创建一个新的文件夹 (例如 `task3`)。
2. 将你完成的所有代码（`.py`和`.ipynb`文件）上传到该文件夹。
3. 通过Pull Request的方式，在课程仓库的 `solutions.md` 文件中更新你的仓库地址。
